# ğŸ§  Asistente Virtual FAUSTO

**FAUSTO** es un asistente virtual conversacional, con capacidad de **voz**, **memoria a largo plazo** (usando RAG con embeddings) y una interfaz grÃ¡fica para gestionar transcripciones y documentos.

---

## ğŸš€ CaracterÃ­sticas principales

* ğŸ§ TranscripciÃ³n de voz con [Whisper](https://github.com/openai/whisper)
* ğŸ—£ï¸ Respuestas habladas usando [Coqui TTS](https://github.com/coqui-ai/TTS)
* ğŸ“€ Almacenamiento de transcripciones y conocimientos en SQLite
* ğŸ§  RecuperaciÃ³n de informaciÃ³n mediante RAG (**Retrieval-Augmented Generation**) con:

  * **Embeddings locales** usando HuggingFace y el modelo `all-MiniLM-L6-v2`
  * Similitud por `cosine similarity` con `scikit-learn`
* âœï¸ Carga de archivos `.txt` y `.docx` como documentos de conocimiento
* ğŸ§¹ IntegraciÃ³n con **Gemma 3** (vÃ­a `ollama`) para generaciÃ³n de respuestas
* ğŸ’¡ Modal de historial y documentos con ediciÃ³n, eliminaciÃ³n y visualizaciÃ³n por pÃ¡ginas

---

## ğŸ“‚ Estructura del proyecto

```
asistente_virtual_fausto/
â”‚
â”œâ”€â”€ assistant/
â”‚   â”œâ”€â”€ app.py              # Servidor principal Flask + Socket.IO
â”‚   â”œâ”€â”€ static/             # JS, CSS, imÃ¡genes
â”‚   â”œâ”€â”€ templates/          # index.html
â”‚   â””â”€â”€ database/
â”‚       â”œâ”€â”€ db_manager.py   # LÃ³gica SQLite
â”‚       â””â”€â”€ fausto.db       # Base de datos
â”œâ”€â”€ venv/                   # Entorno virtual
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Requisitos

Instala los paquetes necesarios:

```bash
pip install flask flask_socketio openai-whisper coqui-tts sentence-transformers scikit-learn python-docx
```

---

## ğŸ¯ Instrucciones de uso

1. Clona el proyecto y entra en la carpeta:

```bash
git clone https://github.com/tu_usuario/asistente_virtual_fausto.git
cd asistente_virtual_fausto
```

2. Inicia el entorno virtual (opcional pero recomendado):

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. Instala dependencias (ver secciÃ³n anterior)
4. Arranca la aplicaciÃ³n:

```bash
python assistant/app.py
```

5. Abre en el navegador:

```
http://localhost:5000
```

---

## ğŸ¤ Flujo de trabajo

### 1. TranscripciÃ³n por voz

* El usuario habla â†’ Whisper transcribe â†’ se muestra en pantalla.

### 2. GeneraciÃ³n de respuesta

* Se busca contexto usando embeddings (MiniLM) y cosine\_similarity.
* Se envÃ­a a Gemma 3 vÃ­a ollama junto con el contexto.
* Se recibe respuesta â†’ se reproduce usando Coqui TTS.

### 3. Almacenamiento

* Se pueden guardar transcripciones y documentos manualmente desde la interfaz.

---

## ğŸ“š Embeddings y RAG

* Los documentos se procesan con el modelo `sentence-transformers/all-MiniLM-L6-V2` local.
* Se almacenan en una tabla `embeddings` vinculada a cada documento.
* Cuando el usuario realiza una pregunta, se recupera el contexto mÃ¡s relevante vÃ­a `cosine_similarity`.

---

## ğŸ—‘ï¸ GestiÃ³n de documentos y transcripciones

* En la interfaz puedes:

  * Ver transcripciones por pÃ¡ginas
  * Expandir texto largo
  * Editar o eliminar documentos con confirmaciÃ³n
  * Cargar archivos `.txt` y `.docx` como conocimiento nuevo

---

## âš ï¸ Requisitos adicionales

* `ffmpeg` debe estar instalado para que Whisper funcione correctamente.
* `ollama` debe estar instalado y funcionando (ej. `ollama run gemma3`).
* Se recomienda usar **Python 3.9+**


1. **Clona el repositorio:**

   ```bash
   git clone https://github.com/JTRC83/asistente_virtual_fausto.git